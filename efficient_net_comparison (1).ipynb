{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtCHJD7SVUH4",
        "outputId": "90b553e5-d7c8-46b4-e76a-f31ac9fff4a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Using device: cuda\n",
            "\n",
            "Training and evaluating EfficientNet-B4...\n",
            "Epoch [1/2], Train Loss: 1.2588, Train Acc: 68.63%\n",
            "Epoch [1/2], Val Acc: 94.12%\n",
            "Epoch [2/2], Train Loss: 0.9637, Train Acc: 98.53%\n",
            "Epoch [2/2], Val Acc: 99.75%\n",
            "\n",
            "Training and evaluating EfficientNet-B5...\n",
            "Epoch [1/2], Train Loss: 0.8473, Train Acc: 86.03%\n",
            "Epoch [1/2], Val Acc: 99.51%\n",
            "Epoch [2/2], Train Loss: 0.1935, Train Acc: 100.00%\n",
            "Epoch [2/2], Val Acc: 100.00%\n",
            "\n",
            "Training and evaluating EfficientNet-V2-S...\n",
            "Epoch [1/2], Train Loss: 0.6029, Train Acc: 89.71%\n",
            "Epoch [1/2], Val Acc: 100.00%\n",
            "Epoch [2/2], Train Loss: 0.0517, Train Acc: 100.00%\n",
            "Epoch [2/2], Val Acc: 100.00%\n",
            "\n",
            "Results have been saved to 'model_comparison_results_.csv'\n",
            "Plots have been saved as 'model_comparison_plots.png'\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.models as models\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import os\n",
        "import time\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "# Google Drive 마운트\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "class DiecastingDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if self.transform:\n",
        "            transformed = self.transform(image=image)\n",
        "            image = transformed['image']\n",
        "\n",
        "        label = self.labels[idx]\n",
        "        return image, label\n",
        "\n",
        "def get_data_paths(data_base_path):\n",
        "    class_dirs = {\n",
        "        'BLDC-400-Back': 0,\n",
        "        'BLDC-400-Front': 1,\n",
        "        'G2': 2,\n",
        "        'CN7': 3\n",
        "    }\n",
        "    paths = []\n",
        "    labels = []\n",
        "\n",
        "    for class_dir, label in class_dirs.items():\n",
        "        class_path = os.path.join(data_base_path, class_dir)\n",
        "        image_files = [os.path.join(class_path, f) for f in os.listdir(class_path)\n",
        "                      if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
        "        paths.extend(image_files)\n",
        "        labels.extend([label] * len(image_files))\n",
        "\n",
        "    return paths, labels\n",
        "\n",
        "# 데이터 전처리 정의 (resize만 사용)\n",
        "transforms = A.Compose([\n",
        "    A.Resize(224, 224),\n",
        "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "def train_model(model, train_loader, val_loader, device, epochs, lr):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    train_start_time = time.time()\n",
        "    best_val_acc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        train_acc = 100. * correct / total\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
        "\n",
        "        # 검증\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        with torch.no_grad():\n",
        "            for val_images, val_labels in val_loader:\n",
        "                val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
        "                val_outputs = model(val_images)\n",
        "                _, val_predicted = val_outputs.max(1)\n",
        "                val_total += val_labels.size(0)\n",
        "                val_correct += val_predicted.eq(val_labels).sum().item()\n",
        "\n",
        "        val_acc = 100. * val_correct / val_total\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Val Acc: {val_acc:.2f}%')\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), f'/content/drive/MyDrive/{model.__class__.__name__}_best.pth')\n",
        "\n",
        "    training_time = time.time() - train_start_time\n",
        "    return best_val_acc, training_time\n",
        "\n",
        "def evaluate_model(model, test_loader, device, class_names):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    inference_times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # 추론 시간 측정\n",
        "            start_time = time.time()\n",
        "            outputs = model(images)\n",
        "            inference_times.append(time.time() - start_time)\n",
        "\n",
        "            _, predicted = outputs.max(1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # 성능 지표 계산\n",
        "    accuracy = 100. * sum(np.array(all_preds) == np.array(all_labels)) / len(all_labels)\n",
        "    avg_inference_time = np.mean(inference_times)\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)\n",
        "\n",
        "    return accuracy, avg_inference_time, cm, report\n",
        "\n",
        "def main():\n",
        "    # 장치 설정\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f'Using device: {device}')\n",
        "\n",
        "    # 데이터 경로 설정\n",
        "    train_base_path = '/content/drive/MyDrive/data_augmented'\n",
        "    test_base_path = '/content/drive/MyDrive/test_data'\n",
        "\n",
        "    # 데이터 로드\n",
        "    train_paths, train_labels = get_data_paths(train_base_path)\n",
        "    test_paths, test_labels = get_data_paths(test_base_path)\n",
        "\n",
        "    # 데이터셋 생성\n",
        "    train_dataset = DiecastingDataset(train_paths, train_labels, transforms)\n",
        "    test_dataset = DiecastingDataset(test_paths, test_labels, transforms)\n",
        "\n",
        "    # 데이터 로더 생성\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    # 클래스 이름 정의\n",
        "    class_names = ['BLDC-400-Back', 'BLDC-400-Front', 'G2', 'CN7']\n",
        "\n",
        "    # 모델 정의\n",
        "    models_to_test = {\n",
        "        'EfficientNet-B4': models.efficientnet_b4(weights='DEFAULT'),\n",
        "        'EfficientNet-B5': models.efficientnet_b5(weights='DEFAULT'),\n",
        "        'EfficientNet-V2-S': models.efficientnet_v2_s(weights='DEFAULT')\n",
        "    }\n",
        "\n",
        "    # 결과 저장용 리스트\n",
        "    results = []\n",
        "\n",
        "    # 각 모델 평가\n",
        "    for model_name, model in models_to_test.items():\n",
        "        print(f'\\nTraining and evaluating {model_name}...')\n",
        "\n",
        "        # 분류층 수정\n",
        "        if 'v2' in model_name.lower():\n",
        "            model.classifier = nn.Linear(model.classifier[1].in_features, 4)\n",
        "        else:\n",
        "            model.classifier[1] = nn.Linear(model.classifier[1].in_features, 4)\n",
        "\n",
        "        model = model.to(device)\n",
        "\n",
        "        # 학습\n",
        "        best_val_acc, training_time = train_model(\n",
        "            model, train_loader, test_loader, device,\n",
        "            epochs=2, lr=1e-4\n",
        "        )\n",
        "\n",
        "        # 테스트셋 평가\n",
        "        accuracy, inf_time, cm, report = evaluate_model(\n",
        "            model, test_loader, device, class_names\n",
        "        )\n",
        "\n",
        "        # 결과 저장\n",
        "        results.append({\n",
        "            'Model': model_name,\n",
        "            'Accuracy': accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Inference Time': inf_time,\n",
        "            'Precision': report['weighted avg']['precision'],\n",
        "            'Recall': report['weighted avg']['recall'],\n",
        "            'F1-Score': report['weighted avg']['f1-score']\n",
        "        })\n",
        "\n",
        "        # 혼동 행렬 저장\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                   xticklabels=class_names, yticklabels=class_names)\n",
        "        plt.title(f'Confusion Matrix - {model_name}')\n",
        "        plt.ylabel('True Label')\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.savefig(f'/content/drive/MyDrive/{model_name}_confusion_matrix_.png')\n",
        "        plt.close()\n",
        "\n",
        "    # 결과 DataFrame 생성 및 저장\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv('/content/drive/MyDrive/model_comparison_results_.csv', index=False)\n",
        "\n",
        "    # 결과 시각화\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # 정확도 비교\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.bar(results_df['Model'], results_df['Accuracy'])\n",
        "    plt.title('Model Accuracy Comparison')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "\n",
        "    # 학습 시간 비교\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.bar(results_df['Model'], results_df['Training Time'])\n",
        "    plt.title('Training Time Comparison')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.ylabel('Time (seconds)')\n",
        "\n",
        "    # F1-Score 비교\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.bar(results_df['Model'], results_df['F1-Score'])\n",
        "    plt.title('F1-Score Comparison')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.ylabel('F1-Score')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/drive/MyDrive/model_comparison_plots_.png')\n",
        "    plt.close()\n",
        "\n",
        "    print(\"\\nResults have been saved to 'model_comparison_results_.csv'\")\n",
        "    print(\"Plots have been saved as 'model_comparison_plots.png'\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ]
}